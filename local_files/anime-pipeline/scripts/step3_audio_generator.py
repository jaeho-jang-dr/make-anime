#!/usr/bin/env python3
"""
=============================================================================
STEP 3: ì˜¤ë””ì˜¤ ìƒì„±ê¸° (Google Cloud TTS + Grok ìŒì•… ì œì•ˆ)
=============================================================================
ì´ ëª¨ë“ˆì€:
- Google Cloud TTSë¡œ ëŒ€ì‚¬/ë‚˜ë ˆì´ì…˜ ìŒì„± ìƒì„±
- íš¨ê³¼ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë§¤ì¹­
- BGM ì¶”ì²œ (Grok í™œìš©)
- ì˜¤ë””ì˜¤ ë¯¹ì‹± ì¤€ë¹„
"""

import os
import json
import base64
import requests
from pathlib import Path
from typing import List, Optional, Dict, Any
from dataclasses import dataclass
import time
import subprocess


@dataclass
class AudioClip:
    """ì˜¤ë””ì˜¤ í´ë¦½ ì •ë³´"""
    clip_id: str
    clip_type: str  # 'dialogue', 'narration', 'sfx', 'bgm'
    text: Optional[str]
    file_path: str
    duration_seconds: float
    scene_number: int
    metadata: Dict[str, Any]


class GoogleTTSGenerator:
    """Google Cloud Text-to-Speech ìƒì„±ê¸°"""
    
    def __init__(self, 
                 api_key: Optional[str] = None,
                 output_dir: str = "audio"):
        
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY") or os.getenv("GOOGLE_TTS_API_KEY")
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # TTS API ì—”ë“œí¬ì¸íŠ¸
        self.tts_url = "https://texttospeech.googleapis.com/v1/text:synthesize"
        
        # ìŒì„± í”„ë¦¬ì…‹ (ì• ë‹ˆë©”ì´ì…˜ìš©)
        self.voice_presets = {
            "young_female": {
                "languageCode": "ko-KR",
                "name": "ko-KR-Wavenet-A",
                "ssmlGender": "FEMALE"
            },
            "young_male": {
                "languageCode": "ko-KR", 
                "name": "ko-KR-Wavenet-C",
                "ssmlGender": "MALE"
            },
            "narrator": {
                "languageCode": "ko-KR",
                "name": "ko-KR-Wavenet-B",
                "ssmlGender": "FEMALE"
            },
            "deep_male": {
                "languageCode": "ko-KR",
                "name": "ko-KR-Wavenet-D",
                "ssmlGender": "MALE"
            },
            # ì¼ë³¸ì–´ ìŒì„± (ì• ë‹ˆë©”ì´ì…˜ ëŠë‚Œ)
            "anime_female_jp": {
                "languageCode": "ja-JP",
                "name": "ja-JP-Wavenet-B",
                "ssmlGender": "FEMALE"
            },
            "anime_male_jp": {
                "languageCode": "ja-JP",
                "name": "ja-JP-Wavenet-D",
                "ssmlGender": "MALE"
            }
        }
        
        # ì˜¤ë””ì˜¤ ì„¤ì •
        self.audio_config = {
            "audioEncoding": "MP3",
            "speakingRate": 1.0,  # ì†ë„ (0.25 ~ 4.0)
            "pitch": 0.0,        # í”¼ì¹˜ (-20.0 ~ 20.0)
            "volumeGainDb": 0.0  # ë³¼ë¥¨ (-96.0 ~ 16.0)
        }
    
    def generate_speech(self,
                        text: str,
                        voice_style: str = "narrator",
                        scene_number: int = 0,
                        clip_type: str = "dialogue",
                        speaking_rate: float = 1.0,
                        pitch: float = 0.0) -> Optional[AudioClip]:
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
        
        if not text or not text.strip():
            return None
        
        print(f"   ğŸ¤ ìŒì„± ìƒì„±: '{text[:30]}...' ({voice_style})")
        
        # ìŒì„± ì„ íƒ
        voice = self.voice_presets.get(voice_style, self.voice_presets["narrator"])
        
        # ì˜¤ë””ì˜¤ ì„¤ì •
        audio_config = self.audio_config.copy()
        audio_config["speakingRate"] = speaking_rate
        audio_config["pitch"] = pitch
        
        # SSMLë¡œ ê°ì • í‘œí˜„ ì¶”ê°€
        ssml_text = self._add_ssml_emotion(text, clip_type)
        
        payload = {
            "input": {"ssml": ssml_text},
            "voice": voice,
            "audioConfig": audio_config
        }
        
        # API í˜¸ì¶œ
        if self.api_key:
            url = f"{self.tts_url}?key={self.api_key}"
        else:
            # API í‚¤ ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜
            return self._simulate_audio(text, scene_number, clip_type, voice_style)
        
        try:
            response = requests.post(url, json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                audio_content = base64.b64decode(result["audioContent"])
                
                # íŒŒì¼ ì €ì¥
                clip_id = f"{clip_type}_{scene_number:03d}_{int(time.time())}"
                file_path = self.output_dir / f"{clip_id}.mp3"
                
                with open(file_path, 'wb') as f:
                    f.write(audio_content)
                
                # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¶”ì • (ëŒ€ëµ 150 ë‹¨ì–´/ë¶„)
                word_count = len(text.split())
                duration = (word_count / 150) * 60 * (1 / speaking_rate)
                
                return AudioClip(
                    clip_id=clip_id,
                    clip_type=clip_type,
                    text=text,
                    file_path=str(file_path),
                    duration_seconds=duration,
                    scene_number=scene_number,
                    metadata={
                        "voice_style": voice_style,
                        "speaking_rate": speaking_rate,
                        "pitch": pitch,
                        "language": voice["languageCode"]
                    }
                )
            else:
                print(f"   âš ï¸ TTS API ì˜¤ë¥˜: {response.status_code}")
                return self._simulate_audio(text, scene_number, clip_type, voice_style)
                
        except Exception as e:
            print(f"   âš ï¸ TTS ì˜¤ë¥˜: {e}")
            return self._simulate_audio(text, scene_number, clip_type, voice_style)
    
    def _add_ssml_emotion(self, text: str, clip_type: str) -> str:
        """SSML ë§ˆí¬ì—…ìœ¼ë¡œ ê°ì • í‘œí˜„ ì¶”ê°€"""
        
        # ê¸°ë³¸ SSML ë˜í¼
        ssml = f'<speak>{text}</speak>'
        
        # ë‚˜ë ˆì´ì…˜ì€ ì²œì²œíˆ, ëŒ€ì‚¬ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ
        if clip_type == "narration":
            ssml = f'<speak><prosody rate="95%">{text}</prosody></speak>'
        elif clip_type == "dialogue":
            # ëŠë‚Œí‘œëŠ” ê°•ì¡°, ë¬¼ìŒí‘œëŠ” í†¤ ì˜¬ë¦¼
            if "!" in text:
                ssml = f'<speak><prosody pitch="+2st" rate="105%">{text}</prosody></speak>'
            elif "?" in text:
                ssml = f'<speak><prosody pitch="+1st">{text}</prosody></speak>'
        
        return ssml
    
    def _simulate_audio(self, text: str, scene_number: int, 
                        clip_type: str, voice_style: str) -> AudioClip:
        """API ì—†ì„ ë•Œ ì‹œë®¬ë ˆì´ì…˜ (ë©”íƒ€ë°ì´í„°ë§Œ ìƒì„±)"""
        
        clip_id = f"{clip_type}_{scene_number:03d}_{int(time.time())}"
        
        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì €ì¥ (ë‚˜ì¤‘ì— TTS ì²˜ë¦¬ìš©)
        script_path = self.output_dir / f"{clip_id}_script.txt"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(f"Voice: {voice_style}\n")
            f.write(f"Type: {clip_type}\n")
            f.write(f"Text: {text}\n")
        
        # ëŒ€ëµì ì¸ ê¸¸ì´ ì¶”ì •
        word_count = len(text.split())
        duration = max(1.0, (word_count / 150) * 60)
        
        return AudioClip(
            clip_id=clip_id,
            clip_type=clip_type,
            text=text,
            file_path=str(script_path),
            duration_seconds=duration,
            scene_number=scene_number,
            metadata={
                "voice_style": voice_style,
                "simulated": True,
                "note": "API í‚¤ ì—†ìŒ - ìŠ¤í¬ë¦½íŠ¸ë§Œ ì €ì¥ë¨"
            }
        )


class SoundEffectManager:
    """íš¨ê³¼ìŒ ê´€ë¦¬ì"""
    
    # ë¬´ë£Œ íš¨ê³¼ìŒ ì†ŒìŠ¤ ë§¤í•‘
    FREE_SFX_SOURCES = {
        "wind": "https://freesound.org/search/?q=wind",
        "footsteps": "https://freesound.org/search/?q=footsteps",
        "magic": "https://freesound.org/search/?q=magic+spell",
        "sword": "https://freesound.org/search/?q=sword+slash",
        "explosion": "https://freesound.org/search/?q=explosion",
        "rain": "https://freesound.org/search/?q=rain+ambient",
        "fire": "https://freesound.org/search/?q=fire+crackling",
        "bells": "https://freesound.org/search/?q=bells",
        "door": "https://freesound.org/search/?q=door+creak",
        "crowd": "https://freesound.org/search/?q=crowd+murmur"
    }
    
    def __init__(self, output_dir: str = "audio/sfx"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.sfx_list = []
    
    def suggest_sfx(self, scene_effects: List[str], scene_number: int) -> List[dict]:
        """ì¥ë©´ì— í•„ìš”í•œ íš¨ê³¼ìŒ ì œì•ˆ"""
        
        suggestions = []
        
        for effect in scene_effects:
            effect_lower = effect.lower()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            matched_source = None
            for keyword, source_url in self.FREE_SFX_SOURCES.items():
                if keyword in effect_lower:
                    matched_source = source_url
                    break
            
            suggestion = {
                "scene_number": scene_number,
                "effect_name": effect,
                "suggested_source": matched_source or f"https://freesound.org/search/?q={effect.replace(' ', '+')}",
                "timing": "match with visual",
                "volume": "0.3-0.5 (ë°°ê²½ìŒ)"
            }
            suggestions.append(suggestion)
        
        return suggestions
    
    def generate_sfx_sheet(self, all_scenes: List[dict]) -> str:
        """ì „ì²´ íš¨ê³¼ìŒ ì‹œíŠ¸ ìƒì„±"""
        
        sheet = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸ”Š íš¨ê³¼ìŒ (SFX) ìˆ˜ì§‘ ê°€ì´ë“œ                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Œ ë¬´ë£Œ íš¨ê³¼ìŒ ì†ŒìŠ¤:
â€¢ Freesound.org (ë¬´ë£Œ, ë¡œê·¸ì¸ í•„ìš”)
â€¢ Pixabay.com/sound-effects (ë¬´ë£Œ, ìƒì—…ìš© ê°€ëŠ¥)
â€¢ Mixkit.co/free-sound-effects (ë¬´ë£Œ)
â€¢ YouTube Audio Library (YouTube Studioì—ì„œ ì ‘ê·¼)

ğŸ“Œ ì¥ë©´ë³„ í•„ìš” íš¨ê³¼ìŒ:
"""
        for scene in all_scenes:
            effects = scene.get("sound_effects", [])
            if effects:
                sheet += f"\nì¥ë©´ {scene.get('scene_number', '?'):03d}: {', '.join(effects)}"
        
        sheet += """

ğŸ“Œ íš¨ê³¼ìŒ íŒ:
â€¢ ë³¼ë¥¨ì€ ëŒ€ì‚¬/ë‚˜ë ˆì´ì…˜ë³´ë‹¤ ë‚®ê²Œ (30-50%)
â€¢ í˜ì´ë“œ ì¸/ì•„ì›ƒ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ
â€¢ ì—¬ëŸ¬ ë ˆì´ì–´ ê²¹ì¹˜ë©´ í’ì„±í•œ ì‚¬ìš´ë“œìŠ¤ì¼€ì´í”„
"""
        return sheet


class GrokMusicAdvisor:
    """Grokì„ í™œìš©í•œ BGM ì¶”ì²œ"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("GROK_API_KEY") or os.getenv("XAI_API_KEY")
        self.base_url = "https://api.x.ai/v1"
    
    def suggest_bgm(self, 
                    scene_mood: str,
                    scene_description: str,
                    genre: str = "anime") -> dict:
        """ì¥ë©´ì— ë§ëŠ” BGM ì¶”ì²œ"""
        
        if not self.api_key:
            return self._default_suggestion(scene_mood)
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        payload = {
            "model": "grok-beta",
            "messages": [
                {
                    "role": "system",
                    "content": """You are a music director for anime. 
Suggest background music for scenes based on mood and description.
Respond in JSON format with:
- mood_category: (action/emotional/peaceful/mysterious/comedic/epic)
- tempo: (slow/medium/fast)
- instruments: [list of suggested instruments]
- reference_tracks: [similar anime OST examples]
- royalty_free_search: search keywords for royalty-free music sites"""
                },
                {
                    "role": "user",
                    "content": f"Scene mood: {scene_mood}\nDescription: {scene_description}\nGenre: {genre}"
                }
            ],
            "max_tokens": 300
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # JSON íŒŒì‹± ì‹œë„
                try:
                    json_start = content.find('{')
                    json_end = content.rfind('}') + 1
                    if json_start != -1:
                        return json.loads(content[json_start:json_end])
                except:
                    pass
                
                return {"raw_suggestion": content}
                
        except Exception as e:
            print(f"Grok API ì˜¤ë¥˜: {e}")
        
        return self._default_suggestion(scene_mood)
    
    def _default_suggestion(self, mood: str) -> dict:
        """ê¸°ë³¸ BGM ì œì•ˆ"""
        
        mood_mapping = {
            "ìš°ìš¸": {"category": "emotional", "tempo": "slow", "search": "sad piano anime"},
            "í¬ë§": {"category": "emotional", "tempo": "medium", "search": "hopeful orchestral anime"},
            "ê¸´ì¥": {"category": "mysterious", "tempo": "medium", "search": "suspense tension anime"},
            "ì „íˆ¬": {"category": "action", "tempo": "fast", "search": "epic battle orchestral"},
            "í‰í™”": {"category": "peaceful", "tempo": "slow", "search": "peaceful ambient anime"},
            "ì‹ ë¹„": {"category": "mysterious", "tempo": "slow", "search": "mysterious fantasy anime"},
            "ìŠ¬í””": {"category": "emotional", "tempo": "slow", "search": "sad emotional piano"},
            "ê¸°ì¨": {"category": "comedic", "tempo": "medium", "search": "happy cheerful anime"}
        }
        
        for key, value in mood_mapping.items():
            if key in mood.lower():
                return {
                    "mood_category": value["category"],
                    "tempo": value["tempo"],
                    "royalty_free_search": value["search"],
                    "suggested_sources": [
                        "https://pixabay.com/music/search/anime/",
                        "https://www.youtube.com/audiolibrary",
                        "https://incompetech.com/music/"
                    ]
                }
        
        return {
            "mood_category": "general",
            "tempo": "medium",
            "royalty_free_search": "anime background music",
            "suggested_sources": ["https://pixabay.com/music/"]
        }
    
    def generate_music_guide(self, scenes: List[dict]) -> str:
        """ì „ì²´ BGM ê°€ì´ë“œ ìƒì„±"""
        
        guide = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸµ BGM (ë°°ê²½ìŒì•…) ê°€ì´ë“œ                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Œ ë¬´ë£Œ BGM ì†ŒìŠ¤:
â€¢ Pixabay Music (https://pixabay.com/music/) - ìƒì—…ìš© ë¬´ë£Œ
â€¢ YouTube Audio Library - YouTube í¬ë¦¬ì—ì´í„°ìš©
â€¢ Incompetech (https://incompetech.com) - Kevin MacLeod ìŒì•…
â€¢ Free Music Archive (https://freemusicarchive.org)

ğŸ“Œ ì¥ë©´ë³„ BGM ì¶”ì²œ:
"""
        for scene in scenes:
            mood = scene.get("mood", "neutral")
            suggestion = self.suggest_bgm(mood, scene.get("description", ""))
            
            guide += f"""
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì¥ë©´ {scene.get('scene_number', '?'):03d} | ë¶„ìœ„ê¸°: {mood}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ ì¹´í…Œê³ ë¦¬: {suggestion.get('mood_category', 'N/A')}
â€¢ í…œí¬: {suggestion.get('tempo', 'N/A')}
â€¢ ê²€ìƒ‰ì–´: {suggestion.get('royalty_free_search', 'anime bgm')}
"""
        
        guide += """
ğŸ“Œ BGM ì‚¬ìš© íŒ:
â€¢ ëŒ€ì‚¬ê°€ ìˆëŠ” ì¥ë©´: BGM ë³¼ë¥¨ 20-30%
â€¢ ë‚˜ë ˆì´ì…˜ ì¥ë©´: BGM ë³¼ë¥¨ 30-40%
â€¢ ì•¡ì…˜/ì „í™˜: BGM ë³¼ë¥¨ 50-70%
â€¢ ì¥ë©´ ì „í™˜ ì‹œ í¬ë¡œìŠ¤í˜ì´ë“œ ì‚¬ìš© (1-2ì´ˆ)
"""
        return guide


def process_script_for_audio(script_path: str, output_dir: str = "/home/claude/anime-pipeline"):
    """ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ ìƒì„±"""
    
    with open(script_path, 'r', encoding='utf-8') as f:
        script = json.load(f)
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    tts_gen = GoogleTTSGenerator(output_dir=f"{output_dir}/audio")
    sfx_manager = SoundEffectManager(output_dir=f"{output_dir}/audio/sfx")
    music_advisor = GrokMusicAdvisor()
    
    print("=" * 60)
    print("ğŸµ ì˜¤ë””ì˜¤ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 60)
    
    all_audio_clips = []
    all_sfx_suggestions = []
    
    # ìºë¦­í„°ë³„ ìŒì„± ìŠ¤íƒ€ì¼ ë§¤í•‘
    character_voices = {}
    for char in script.get("characters", []):
        voice_style = char.get("voice_style", "narrator")
        # ê°„ë‹¨í•œ ë§¤í•‘
        if "female" in voice_style.lower() or "girl" in voice_style.lower():
            character_voices[char["name"]] = "young_female"
        elif "male" in voice_style.lower() or "deep" in voice_style.lower():
            character_voices[char["name"]] = "deep_male"
        else:
            character_voices[char["name"]] = "narrator"
    
    print(f"\nğŸ“Œ ìºë¦­í„° ìŒì„± ë§¤í•‘: {character_voices}")
    
    # ì¥ë©´ë³„ ì˜¤ë””ì˜¤ ì²˜ë¦¬
    print("\nğŸ“Œ Phase 1: ëŒ€ì‚¬/ë‚˜ë ˆì´ì…˜ ìŒì„± ìƒì„±")
    for scene in script.get("scenes", []):
        scene_num = scene["scene_number"]
        
        # ë‚˜ë ˆì´ì…˜
        if scene.get("narration"):
            clip = tts_gen.generate_speech(
                text=scene["narration"],
                voice_style="narrator",
                scene_number=scene_num,
                clip_type="narration",
                speaking_rate=0.95
            )
            if clip:
                all_audio_clips.append(clip)
        
        # ëŒ€ì‚¬
        if scene.get("dialogue"):
            clip = tts_gen.generate_speech(
                text=scene["dialogue"],
                voice_style="young_female",  # ê¸°ë³¸ê°’
                scene_number=scene_num,
                clip_type="dialogue"
            )
            if clip:
                all_audio_clips.append(clip)
        
        # íš¨ê³¼ìŒ ì œì•ˆ
        if scene.get("sound_effects"):
            sfx = sfx_manager.suggest_sfx(scene["sound_effects"], scene_num)
            all_sfx_suggestions.extend(sfx)
    
    print(f"   âœ“ {len(all_audio_clips)}ê°œ ìŒì„± í´ë¦½ ìƒì„±/ì¤€ë¹„ë¨")
    
    # íš¨ê³¼ìŒ ê°€ì´ë“œ ìƒì„±
    print("\nğŸ“Œ Phase 2: íš¨ê³¼ìŒ ê°€ì´ë“œ ìƒì„±")
    sfx_sheet = sfx_manager.generate_sfx_sheet(script.get("scenes", []))
    sfx_path = Path(output_dir) / "audio" / "SFX_GUIDE.txt"
    with open(sfx_path, 'w', encoding='utf-8') as f:
        f.write(sfx_sheet)
    print(f"   âœ“ íš¨ê³¼ìŒ ê°€ì´ë“œ ì €ì¥ë¨")
    
    # BGM ê°€ì´ë“œ ìƒì„±
    print("\nğŸ“Œ Phase 3: BGM ê°€ì´ë“œ ìƒì„±")
    bgm_guide = music_advisor.generate_music_guide(script.get("scenes", []))
    bgm_path = Path(output_dir) / "audio" / "BGM_GUIDE.txt"
    with open(bgm_path, 'w', encoding='utf-8') as f:
        f.write(bgm_guide)
    print(f"   âœ“ BGM ê°€ì´ë“œ ì €ì¥ë¨")
    
    # ì˜¤ë””ì˜¤ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì €ì¥
    manifest = {
        "total_clips": len(all_audio_clips),
        "clips": [
            {
                "clip_id": c.clip_id,
                "type": c.clip_type,
                "scene": c.scene_number,
                "duration": c.duration_seconds,
                "file": c.file_path,
                "text": c.text
            }
            for c in all_audio_clips
        ],
        "sfx_suggestions": all_sfx_suggestions
    }
    
    manifest_path = Path(output_dir) / "audio" / "audio_manifest.json"
    with open(manifest_path, 'w', encoding='utf-8') as f:
        json.dump(manifest, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 60)
    print("âœ… ì˜¤ë””ì˜¤ ì¤€ë¹„ ì™„ë£Œ!")
    print("=" * 60)
    
    return manifest


if __name__ == "__main__":
    script_path = "/home/claude/anime-pipeline/scripts/sample_script.json"
    
    if Path(script_path).exists():
        result = process_script_for_audio(script_path)
        print(f"\nìƒì„±ëœ í•­ëª©:")
        print(f"  - ì˜¤ë””ì˜¤ í´ë¦½: {result['total_clips']}ê°œ")
        print(f"  - íš¨ê³¼ìŒ ì œì•ˆ: {len(result['sfx_suggestions'])}ê°œ")
    else:
        print(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {script_path}")
